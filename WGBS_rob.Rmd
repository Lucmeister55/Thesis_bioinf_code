```{r}
# Clear memory
rm(list = ls())
gc()

# Load necessary library
library(methylKit)
library(dplyr)
library(tidyverse)
library(glmnet)
library(limma)
library(GenomicRanges)

# Define directory
dir <- "/data/lvisser/wgbs_lvisser"

metadata <- read.csv("/data/lvisser/wgbs_lvisser/metadata.csv")

# Get list of all .cov.gz files in the directory
file.list <- list.files(path = dir, pattern = "\\.cov\\.gz$", full.names = TRUE)

sample.id.list <- as.list(gsub(".bismark.cov.gz", "", basename(file.list)))

labels <- metadata$label[match(sample.id.list, metadata$ohmx_id)]

labels_encoded <- ifelse(labels == 'R', 1, 0)

# Loop over each sample ID
for(id in sample.id.list) {
  # Create the directory path
  dir_path <- file.path(dir, id)
  
  # Create the directory if it doesn't exist
  if(!dir.exists(dir_path)) {
    dir.create(dir_path)
  }
}

# Create the directory path
united_path <- file.path(dir, "united")
  
# Create the directory if it doesn't exist
if(!dir.exists(united_path)) {
  dir.create(united_path)
}

# Existing code
myobj <- methRead(location = as.list(file.list), sample.id = sample.id.list, assembly = "hg38", context="CpG", treatment = labels_encoded, pipeline = "bismarkCoverage")

total_coverage <- 0
total_samples <- length(myobj)

for(i in seq_along(myobj)) {
  png(paste0(dir, "/", sample.id.list[[i]], "/methylation_stats_", sample.id.list[[i]], ".png"))
  getMethylationStats(myobj[[i]],plot=TRUE,both.strands=FALSE)
  dev.off()

  png(paste0(dir, "/", sample.id.list[[i]], "/coverage_stats_", sample.id.list[[i]], ".png"))
  getCoverageStats(myobj[[i]],plot=TRUE,both.strands=FALSE)
  dev.off()

  coverage_stats <- getCoverageStats(myobj[[i]], both.strands=FALSE)

  # New code to calculate total coverage
  total_coverage <- total_coverage + coverage_stats$total
}

# New code to calculate and print average coverage
average_coverage <- total_coverage / total_samples
print(average_coverage)

filtered.myobj <- filterByCoverage(myobj,lo.count=10,lo.perc=NULL,hi.count=NULL,hi.perc=99.9)

myobj <- normalizeCoverage(filtered.myobj)
```

```{r}
meth = methylKit::unite(myobj, destrand = FALSE)

png(paste0(united_path, "/correlation.png"))
getCorrelation(meth,plot=TRUE)
dev.off()

png(paste0(united_path, "/clustersamples.png"))
clusterSamples(meth, dist="correlation", method="ward", plot=TRUE)
dev.off()

png(paste0(united_path, "/pcasamples_screeplot.png"))
PCASamples(meth, screeplot=TRUE)
dev.off()

png(paste0(united_path, "/pcasamples.png"))
PCASamples(meth)
dev.off()
```

```{r}
pm=percMethylation(meth) # get percent methylation matrix
mds=matrixStats::rowSds(pm)

png(paste0(united_path, "/mds.png"))
hist(mds,col="cornflowerblue",xlab="Std. dev. per CpG")
dev.off()

# Get the number of samples
num_samples <- ncol(pm)

# Generate the new column names
new_colnames <- paste0("beta", seq_len(num_samples))

betas <- pm / 100

# Assign the new column names to pm
colnames(betas) <- new_colnames
```

```{r}
meth_granges <- as(meth,"GRanges")

segmented.grangeslist <- GRangesList()
segmented.concat <- c()

for (i in 1:length(sample.id.list)) {
  mcols(meth_granges)[, paste0("beta", i)] <- betas[, paste0("beta", i)]
  meth_granges_sample <- meth_granges[, paste0("beta", i)]
  png(paste0(dir, "/", sample.id.list[[i]], "/diagnostic_plot_", sample.id.list[[i]], ".png"))
  segmented_sample <- methSeg(meth_granges_sample, diagnostic.plot=TRUE, minSeg=10, maxInt = 100, G = 1:10)
  dev.off()
  segmented.grangeslist[[sample.id.list[[i]]]] <- segmented_sample
}

segmented.concat <- Reduce(c, segmented.grangeslist)

# Initialize the result with the first GRanges object in the list
intersected.granges <- segmented.grangeslist[[1]]

# Loop over the rest of the GRanges objects in the list
for (i in 2:length(segmented.grangeslist)) {
  # Intersect the current result with the current GRanges object
  intersected.granges <- GenomicRanges::intersect(intersected.granges, segmented.grangeslist[[i]])
}

# Now intersected.granges contains the intersection of all GRanges objects in the list
segmented.consensus <- intersected.granges

# segmented.consensus <- GenomicRanges::disjoin(segmented.concat, ignore.strand=TRUE)
mcols(segmented.consensus)$width <- width(segmented.consensus)

# New code to remove rows with width larger than 2000 and smaller than 3
segmented.consensus <- segmented.consensus[!(segmented.consensus$width > 2000 | segmented.consensus$width < 3)]

print(mean(segmented.consensus$width))
print(median(segmented.consensus$width))
```

```{r}
# Find which segments in meth overlap with each segment in segmented.consensus
overlaps <- findOverlaps(meth_granges, segmented.consensus)

for (i in 1:length(sample.id.list)) {
  # Create a vector of NA values of the same length as the number of segments
  beta_values_all <- rep(NA, length(segmented.consensus))

  # Calculate the mean beta value for each segment
  beta_values <- tapply(mcols(meth_granges)[, paste0("beta", i)][queryHits(overlaps)], subjectHits(overlaps), mean)
  
  # Get the indices of segmented.consensus that correspond to the overlapping segments
  overlap_indices <- match(subjectHits(overlaps), seq_along(segmented.consensus))
  
  # Replace the elements that correspond to overlapping segments with the calculated mean beta values
  beta_values_all[unique(overlap_indices)] <- beta_values

  # Add the beta values to the metadata columns of segmented.consensus
  mcols(segmented.consensus)[, sample.id.list[[i]]] <- beta_values_all
}
```

```{r}
# Convert the GRanges object to a data frame
segmented_df <- as.data.frame(segmented.consensus) %>%
    mutate(segment_id = paste0("chr", seqnames, ":", start, "-", end)) %>%
    na.omit()

write.csv(segmented_df, file = "rwgbs_seg_rob.csv", row.names = FALSE)

segmented_fm <- segmented_df %>%
    select(segment_id, starts_with("OHMX")) %>%
    pivot_longer(cols = starts_with("OHMX"), names_to = "ohmx_id", values_to = "value") %>%
    pivot_wider(names_from = segment_id, values_from = value) %>%
    left_join(metadata, by = "ohmx_id") %>%
    select(label, everything())

segmented_fm[1:3, 1:5]

# Save the transposed data
write.csv(segmented_fm, file = "meth_seg_rwgbs_rob_fm.csv", row.names = FALSE)

print(dim(segmented_fm))
```

```{r}
train_and_test_model <- function(data, dmr = FALSE, diff_threshold = 0.1, p_value_threshold = 0.05, reg = FALSE, loocv = FALSE, test_index = NULL) {
  # Separate features and metadata
  features <- data[, sapply(data, is.numeric)]
  metadata <- data[, sapply(data, is.character)]
  
  # Encode labels: 'R' as 1 and 'S' as 0
  metadata$label_encoded <- ifelse(metadata$label == 'R', 1, 0)
  
  # Initialize an empty list to store the results
  results <- list()

  if (loocv) {
    # Loop over each row in the data for LOOCV
    for (i in 1:nrow(features)) {
      # Split the data into a training set and a test set
      train_features <- features[-i, ]
      test_features <- features[i, ]
      train_label <- metadata$label_encoded[-i]
      test_label <- metadata$label_encoded[i]
      
      results[[i]] <- perform_analysis(train_features, test_features, train_label, test_label, dmr, diff_threshold, p_value_threshold, reg)
    }
  } else {
    # Use predefined train and test indices for a single run
    train_features <- features[-test_index, ]
    test_features <- features[test_index, ]
    train_label <- metadata$label_encoded[-test_index]
    test_label <- metadata$label_encoded[test_index]
    
    results[[1]] <- perform_analysis(train_features, test_features, train_label, test_label, dmr, diff_threshold, p_value_threshold, reg)
  }

  # Return the results
  return(results)
}

perform_analysis <- function(train_features, test_features, train_label, test_label, dmr = FALSE, diff_threshold = 0.1, p_value_threshold = 0.05, reg = FALSE) {
  # Print number of features before DMR
  print(paste("Number of starting features: ", ncol(train_features)))
  
  if (dmr) {
    # Apply t-test to each feature and calculate average difference
    test_results <- apply(train_features, 2, function(x) {
        group1 <- x[train_label == unique(train_label)[1]]
        group2 <- x[train_label == unique(train_label)[2]]
        avg_diff <- abs(mean(group1) - mean(group2))
        
        if (length(group1) > 1 || length(group2) > 1) {
            p_value <- t.test(group1, group2)$p.value
        } else {
            p_value <- ifelse(avg_diff > diff_threshold, 0, 1)
        }
        
        return(c(p_value, avg_diff))
    })
    
    # Convert to data frame
    test_results <- as.data.frame(t(test_results))
    colnames(test_results) <- c("p_value", "avg_diff")
    
    # Adjust p-values for multiple testing
    test_results$p_value <- p.adjust(test_results$p_value, method = "fdr")
    
    # Get features with adjusted p-value < 0.05 and average difference > threshold
    top_features <- rownames(test_results)[test_results$p_value < p_value_threshold & test_results$avg_diff > diff_threshold]
  
    # Print number of features after DMR
    print(paste("Number of features after DMR: ", length(top_features)))
  } else {
    top_features <- colnames(train_features)
  }
  
  # Fit an elastic net model on the training set if there are more than one sample per class
  x <- as.data.frame(train_features[, top_features])
  y <- train_label
  
  if (reg) {
    cvfit <- cv.glmnet(x, y, family = "binomial", alpha = 0.5)
    # Test the model on the test set
    test_x <- as.matrix(test_features[, top_features])
    test_y <- test_label
    pred <- predict(cvfit, s = cvfit$lambda.min, newx = test_x)
  } else {
    # If there's only one sample per class, use logistic regression instead
    fit <- glm(y ~ ., data = data.frame(x, y = y), family = binomial())
    print("Model fitted successfully.")

    # Print the summary of the model
    summary_fit <- summary(fit)
    print(summary_fit)
    
    # Test the model on the test set
    test_x <- as.matrix(test_features[, top_features])
    test_y <- test_label

    # Convert test_x to a data frame and replace all colons and dashes in the column names with periods
    test_x <- as.data.frame(test_x)
    colnames(test_x) <- gsub("[:|-]", ".", colnames(test_x))

    newdata <- cbind(y = test_y, test_x)

    pred <- predict(fit, newdata = newdata, type = "response")
    print("Prediction completed successfully.")
  }
  
  # Return the results
  return(list("prediction" = pred, "actual" = test_y))
}
```

```{r}
# Perform leave-one-out cross-validation
results <- train_and_test_model(segmented_fm, test_index = 1, diff_threshold = 0.1, reg = TRUE)

# Calculate the accuracy
accuracy <- sapply(results, function(x) mean((x$prediction > 0.5) == x$actual))

# Print the accuracy
accuracy
```